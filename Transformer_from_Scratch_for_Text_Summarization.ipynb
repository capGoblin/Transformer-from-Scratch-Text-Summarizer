{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/capGoblin/Transformer-from-Scratch-Text_Summarizer/blob/main/Transformer_from_Scratch_for_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 The TensorFlow Authors.\n",
        "\n",
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:12.919884Z",
          "iopub.execute_input": "2023-07-12T15:22:12.920293Z",
          "iopub.status.idle": "2023-07-12T15:22:12.925892Z",
          "shell.execute_reply.started": "2023-07-12T15:22:12.920244Z",
          "shell.execute_reply": "2023-07-12T15:22:12.924657Z"
        },
        "trusted": true,
        "id": "zC2rFTCQqhss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifications Copyright (C) 2020 Rohan Jagtap"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:12.931657Z",
          "iopub.execute_input": "2023-07-12T15:22:12.932356Z",
          "iopub.status.idle": "2023-07-12T15:22:12.939898Z",
          "shell.execute_reply.started": "2023-07-12T15:22:12.932314Z",
          "shell.execute_reply": "2023-07-12T15:22:12.939123Z"
        },
        "trusted": true,
        "id": "FOEn6ZM1qhsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cd /content/drive/My Drive/Colab Notebooks/summarizer_transformer/"
      ],
      "metadata": {
        "id": "ImPCIsrTE5sF",
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:12.942503Z",
          "iopub.execute_input": "2023-07-12T15:22:12.943353Z",
          "iopub.status.idle": "2023-07-12T15:22:12.952901Z",
          "shell.execute_reply.started": "2023-07-12T15:22:12.943298Z",
          "shell.execute_reply": "2023-07-12T15:22:12.951875Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW2vM63xqpjF",
        "outputId": "a3349687-6aba-4b92-c0f2-6d6332944e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.15)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.16)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "BymxhVa7rEzy",
        "outputId": "e26e5cf3-0de9-412a-8406-17ceb599df22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-25e1a5dc-bd4f-4f86-8d70-aadbb376a62a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-25e1a5dc-bd4f-4f86-8d70-aadbb376a62a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "CE-xt4TBrE8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "id": "sCcgB2HirKwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d shashichander009/inshorts-news-data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n77uBcgkrMV5",
        "outputId": "ca4e6645-858a-4559-df3f-3bef918c3b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading inshorts-news-data.zip to /content\n",
            "\r  0% 0.00/12.6M [00:00<?, ?B/s]\r 72% 9.00M/12.6M [00:00<00:00, 85.0MB/s]\n",
            "\r100% 12.6M/12.6M [00:00<00:00, 101MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/inshorts-news-data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXREPFsuBPfS",
        "outputId": "a0ad381a-f5d4-463c-8615-1191ef805601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/inshorts-news-data.zip\n",
            "  inflating: Inshorts Cleaned Data.xlsx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, LayerNormalization, Layer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers.schedules import LearningRateSchedule\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.train import Checkpoint, CheckpointManager\n",
        "from tensorflow.keras.metrics import Mean"
      ],
      "metadata": {
        "id": "Zbxhyl_zFlWL",
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:12.954829Z",
          "iopub.execute_input": "2023-07-12T15:22:12.955268Z",
          "iopub.status.idle": "2023-07-12T15:22:21.691466Z",
          "shell.execute_reply.started": "2023-07-12T15:22:12.955227Z",
          "shell.execute_reply": "2023-07-12T15:22:21.690200Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data"
      ],
      "metadata": {
        "id": "yH5cg5pSIHaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/Inshorts Cleaned Data.xlsx', sheet_name='Sheet1', usecols=[0,1])"
      ],
      "metadata": {
        "id": "K_AjGkWXITKA",
        "execution": {
          "iopub.status.busy": "2023-07-12T15:22:21.693308Z",
          "iopub.execute_input": "2023-07-12T15:22:21.694108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "S-rYZhayIe9x",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oXtxc-toIc94",
        "outputId": "126183de-7295-42ff-efb5-5b2da0c367a9",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Headline  \\\n",
              "0  4 ex-bank officials booked for cheating bank o...   \n",
              "1     Supreme Court to go paperless in 6 months: CJI   \n",
              "2  At least 3 killed, 30 injured in blast in Sylh...   \n",
              "3  Why has Reliance been barred from trading in f...   \n",
              "4  Was stopped from entering my own studio at Tim...   \n",
              "\n",
              "                                               Short  \n",
              "0  The CBI on Saturday booked four former officia...  \n",
              "1  Chief Justice JS Khehar has said the Supreme C...  \n",
              "2  At least three people were killed, including a...  \n",
              "3  Mukesh Ambani-led Reliance Industries (RIL) wa...  \n",
              "4  TV news anchor Arnab Goswami has said he was t...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-02768264-02ac-4f96-859f-f9708b15a6e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Short</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
              "      <td>The CBI on Saturday booked four former officia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
              "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
              "      <td>At least three people were killed, including a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why has Reliance been barred from trading in f...</td>\n",
              "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Was stopped from entering my own studio at Tim...</td>\n",
              "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02768264-02ac-4f96-859f-f9708b15a6e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-c477f504-317d-459a-bd5c-c5c5ba3e3c27\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c477f504-317d-459a-bd5c-c5c5ba3e3c27')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-c477f504-317d-459a-bd5c-c5c5ba3e3c27 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02768264-02ac-4f96-859f-f9708b15a6e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02768264-02ac-4f96-859f-f9708b15a6e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR2hg9themaN",
        "outputId": "ecb98f41-be79-4b2f-c38d-8441d15019de",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "news = data['Short']\n",
        "summary = data['Headline']"
      ],
      "metadata": {
        "id": "d4cEp3wmI2BX",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news[30], summary[30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z55AhpKIdK7",
        "outputId": "51aec78c-6159-46a4-bc07-b6ff0fc117cd",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('According to the Guinness World Records, the most generations alive in a single family have been seven.  The difference between the oldest and the youngest person in the family was about 109 years, when Augusta Bunge&#39;s great-great-great-great grandson was born on January 21, 1989. The family belonged to the United States of America.',\n",
              " 'The most generations alive in a single family have been 7')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "f8gKyq1gIq4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for decoder sequence\n",
        "# summary = summary.apply(lambda x: '<START> ' + x + ' <END>')\n",
        "# summary.head()\n",
        "\n",
        "\n",
        "def add_tokens(x):\n",
        "    return '<START> ' + x + ' <END>'\n",
        "\n",
        "summary = summary.apply(add_tokens)\n",
        "print(\"Summary after adding tokens:\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ6LE4MrJjC_",
        "outputId": "c4e94234-2d9b-42c9-e4e6-9dd420d139ed",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary after adding tokens:\n",
            "0        <START> 4 ex-bank officials booked for cheatin...\n",
            "1        <START> Supreme Court to go paperless in 6 mon...\n",
            "2        <START> At least 3 killed, 30 injured in blast...\n",
            "3        <START> Why has Reliance been barred from trad...\n",
            "4        <START> Was stopped from entering my own studi...\n",
            "                               ...                        \n",
            "55099    <START> Sensex loses 400 points to hit 52-week...\n",
            "55100    <START> China to inject $91 bn into the money ...\n",
            "55101    <START> Ghulam Ali set to make acting debut in...\n",
            "55102    <START> IS acknowledges death of Jihadi John: ...\n",
            "55103    <START> Cairn to seek $600 mn from India in da...\n",
            "Name: Headline, Length: 55104, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizing the texts into integer tokens"
      ],
      "metadata": {
        "id": "95Zv7FIvKbTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'\n",
        "\n",
        "news_tokenizer = Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = Tokenizer(filters=filters, oov_token=oov_token)\n",
        "\n",
        "news_tokenizer.fit_on_texts(news)\n",
        "summary_tokenizer.fit_on_texts(summary)\n",
        "\n",
        "inputs = news_tokenizer.texts_to_sequences(news)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "metadata": {
        "id": "7TqbpEyPMRqa",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWU9Xu7OKVab",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ESm-aYR-tvx",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.texts_to_sequences([\"This is a test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVyErXAei5_b",
        "outputId": "ceae322c-ce28-4bf4-f7a0-1df586d4b7d6",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[184, 22, 12, 71]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_tokenizer.sequences_to_texts([[2, 22, 12, 71]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryx9qx90jwXu",
        "outputId": "88b4c452-3be0-4676-c1ea-e0d2dfab4d92",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> is a test']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_vocab_size = len(news_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoizyBvLKv8h",
        "outputId": "43148333-6f80-4c94-c682-7f9440b4fc16",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76362, 29661)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Obtaining insights on lengths for defining maxlen"
      ],
      "metadata": {
        "id": "mZden_q9_eZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_lengths = []\n",
        "summary_lengths = []\n",
        "\n",
        "for n,s in zip(news, summary):\n",
        "    news_lengths.append(len(n))\n",
        "    summary_lengths.append(len(s))\n",
        "\n",
        "\n",
        "\n",
        "news_lengths = pd.Series(news_lengths)\n",
        "summary_lengths = pd.Series(summary_lengths)\n"
      ],
      "metadata": {
        "id": "ma4o2nGdK5Xb",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_lengths.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXZlO99C-UXK",
        "outputId": "6171418f-b9eb-4624-f664-6816ad6d30cc",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean       368.003049\n",
              "std         26.235510\n",
              "min        280.000000\n",
              "25%        350.000000\n",
              "50%        369.000000\n",
              "75%        387.000000\n",
              "max        469.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_lengths.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALMwKMx--ZF7",
        "outputId": "c453e783-7284-4f76-c914-631b9bc98c7b",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean        65.620282\n",
              "std          7.267463\n",
              "min         22.000000\n",
              "25%         61.000000\n",
              "50%         65.000000\n",
              "75%         71.000000\n",
              "max         98.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# maxlen\n",
        "# taking values > and round figured to 75th percentile\n",
        "# at the same time not leaving high variance\n",
        "encoder_maxlen = 400\n",
        "decoder_maxlen = 75"
      ],
      "metadata": {
        "id": "cVeMilXr-bpC",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Padding/Truncating sequences for identical sequence lengths"
      ],
      "metadata": {
        "id": "_SWap3YJBk-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "targets = pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ],
      "metadata": {
        "id": "vEyUBeu7ACRt",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating ds pipeline"
      ],
      "metadata": {
        "id": "wIP0kIIcB8Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.cast(inputs, dtype=tf.int32)\n",
        "targets = tf.cast(targets, dtype=tf.int32)"
      ],
      "metadata": {
        "id": "LzO6l3-AB7hJ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "slZ5f4P4DurS",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "wI-fV7eABWN6",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for inputs , targets in enumerate(ds):\n",
        "    print(inputs)\n",
        "    print(targets)\n",
        "    count+=1\n",
        "\n",
        "    if count > 2:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BIbubkLeZOf",
        "outputId": "c4144b3a-e0c8-4503-fd62-e51778f2e276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(<tf.Tensor: shape=(64, 400), dtype=int32, numpy=\n",
            "array([[  164,   380,   178, ...,     0,     0,     0],\n",
            "       [    2,   347,    82, ...,     0,     0,     0],\n",
            "       [ 2051,     6,    52, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  170, 19239,  9864, ...,     0,     0,     0],\n",
            "       [  370,   841,   372, ...,     0,     0,     0],\n",
            "       [  520,  2961,  3926, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(64, 75), dtype=int32, numpy=\n",
            "array([[    2,   386,     4, ...,     0,     0,     0],\n",
            "       [    2,    82,   781, ...,     0,     0,     0],\n",
            "       [    2,  2855,  1055, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [    2, 10631,  8464, ...,     0,     0,     0],\n",
            "       [    2,   360,  2679, ...,     0,     0,     0],\n",
            "       [    2,  2265,   168, ...,     0,     0,     0]], dtype=int32)>)\n",
            "1\n",
            "(<tf.Tensor: shape=(64, 400), dtype=int32, numpy=\n",
            "array([[11450,    13,   468, ...,     0,     0,     0],\n",
            "       [ 9063,    13,    34, ...,     0,     0,     0],\n",
            "       [ 1866,     5,  1094, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  114,     4,    11, ...,     0,     0,     0],\n",
            "       [    2,  1984,    46, ...,     0,     0,     0],\n",
            "       [  340,     5,   780, ...,     0,     0,     0]], dtype=int32)>, <tf.Tensor: shape=(64, 75), dtype=int32, numpy=\n",
            "array([[    2,  5617, 21875, ...,     0,     0,     0],\n",
            "       [    2,  9282,  2655, ...,     0,     0,     0],\n",
            "       [    2,   559,    22, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [    2,   112,   125, ...,     0,     0,     0],\n",
            "       [    2,   769,  1207, ...,     0,     0,     0],\n",
            "       [    2, 13798,   574, ...,     0,     0,     0]], dtype=int32)>)\n",
            "2\n",
            "(<tf.Tensor: shape=(64, 400), dtype=int32, numpy=\n",
            "array([[   7,  525,  739, ...,    0,    0,    0],\n",
            "       [  25,  470, 1885, ...,    0,    0,    0],\n",
            "       [1944,   13,  307, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [  48,   77, 5692, ...,    0,    0,    0],\n",
            "       [   2, 1689,  157, ...,    0,    0,    0],\n",
            "       [ 380,  178,  108, ...,    0,    0,    0]], dtype=int32)>, <tf.Tensor: shape=(64, 75), dtype=int32, numpy=\n",
            "array([[   2, 3134, 1150, ...,    0,    0,    0],\n",
            "       [   2, 8126, 3916, ...,    0,    0,    0],\n",
            "       [   2,  594,   96, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,  795,   80, ...,    0,    0,    0],\n",
            "       [   2, 3146,   38, ...,    0,    0,    0],\n",
            "       [   2,   24,   19, ...,    0,    0,    0]], dtype=int32)>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset created:\")\n",
        "print(\"Number of batches in the dataset:\", tf.data.experimental.cardinality(ds))\n",
        "print(\"Batch size:\", BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgWDliiTedJS",
        "outputId": "2895f5b4-be0c-44fd-df44-2083bd876003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset created:\n",
            "Number of batches in the dataset: tf.Tensor(861, shape=(), dtype=int64)\n",
            "Batch size: 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding for adding notion of position among words as unlike RNN this is non-directional"
      ],
      "metadata": {
        "id": "isN1CpAXLfsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ],
      "metadata": {
        "id": "Purv7oyhETDZ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def positional_encoding(position, d_model):\n",
        "#     angle_rads = get_angles(\n",
        "#         np.arange(position)[:, np.newaxis],\n",
        "#         np.arange(d_model)[np.newaxis, :],\n",
        "#         d_model\n",
        "#     )\n",
        "\n",
        "#     # apply sin to even indices in the array; 2i\n",
        "#     angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "#     # apply cos to odd indices in the array; 2i+1\n",
        "#     angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "#     pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "#     return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    position = np.arange(position)[:, np.newaxis]\n",
        "    i = np.arange(d_model)[np.newaxis, :]\n",
        "\n",
        "    exponent = (2 * (i // 2)) / np.float32(d_model)\n",
        "#     print(exponent.shape)\n",
        "    # Create angle values for each position and dimension\n",
        "    angle_rates = 1 / np.power(10000, exponent)\n",
        "#     print(angle_rates.shape)\n",
        "    # Compute the angle values for the positions\n",
        "    angle_rads = position * angle_rates\n",
        "#     print(angle_rads.shape)\n",
        "    # Apply sine to even indices\n",
        "    angle_rads[:, ::2] = np.sin(angle_rads[:, ::2])\n",
        "\n",
        "    # Apply cosine to odd indices\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "#     print(angle_rads.shape)\n",
        "    # Add an extra dimension to the array\n",
        "    pos_encoding = np.expand_dims(angle_rads, axis=0)\n",
        "#     print(pos_encoding.shape)\n",
        "\n",
        "    # Convert to TensorFlow float32 data type\n",
        "    pos_encoding = tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "    return pos_encoding"
      ],
      "metadata": {
        "id": "40J2pc2NEXp5",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Masking\n",
        "\n",
        "- Padding mask for masking \"pad\" sequences\n",
        "- Lookahead mask for masking future words from contributing in prediction of current words in self attention"
      ],
      "metadata": {
        "id": "24Pe01DMMWHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_padding_mask(seq):\n",
        "#     seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "#     return seq[:, tf.newaxis, tf.newaxis, :]"
      ],
      "metadata": {
        "id": "hN1wVQAdMVYy",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_look_ahead_mask(size):\n",
        "#     mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "#     return mask"
      ],
      "metadata": {
        "id": "UmjAPLWuMREE",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "    padding_mask = tf.math.equal(seq, 0)\n",
        "    padding_mask = tf.cast(padding_mask, tf.float32)\n",
        "\n",
        "    padding_mask = tf.expand_dims(padding_mask, axis=1)\n",
        "    padding_mask = tf.expand_dims(padding_mask, axis=2)\n",
        "    return padding_mask\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    ones = tf.ones((size, size))\n",
        "\n",
        "    req_matrix = tf.linalg.band_part(ones, -1, 0)\n",
        "    toggle_req_matrix = 1 - req_matrix\n",
        "    mask = toggle_req_matrix\n",
        "    return mask"
      ],
      "metadata": {
        "id": "Q2RXbjg76FL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the Model"
      ],
      "metadata": {
        "id": "n8DqUBc4NFOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaled Dot Product"
      ],
      "metadata": {
        "id": "WfknVF7hNKf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled += (mask * -1e9)\n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled, axis=-1)\n",
        "\n",
        "    values = tf.matmul(attention_weights, v)\n",
        "    return values, attention_weights"
      ],
      "metadata": {
        "id": "w_B6M9OBNBKB",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-Headed Attention"
      ],
      "metadata": {
        "id": "Rf7_a5uQOfJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "\n",
        "#         assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.head_dim = d_model // self.num_heads\n",
        "\n",
        "        self.wq = Dense(d_model)\n",
        "        self.wk = Dense(d_model)\n",
        "        self.wv = Dense(d_model)\n",
        "\n",
        "        self.linear_dense = Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.head_dim))\n",
        "        # x = tf.reshape(x, (batch_size, seq_len, self.num_heads, self.head_dim))\n",
        "\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, q, k, v, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "        # seq_len = tf.shape(q)[1]\n",
        "        # print(q.shape)\n",
        "\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        # q = self.split_heads(q, batch_size, seq_len)\n",
        "        # k = self.split_heads(k, batch_size, seq_len)\n",
        "        # v = self.split_heads(v, batch_size, seq_len)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        values, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "\n",
        "        values = tf.transpose(values, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_values = tf.reshape(values, (batch_size, -1, self.d_model))\n",
        "        # concat_values = tf.reshape(values, (batch_size, seq_len, self.d_model))\n",
        "\n",
        "        output = self.linear_dense(concat_values)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "iIuFrdXnNZEC",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feed Forward Network"
      ],
      "metadata": {
        "id": "A49tXMVvOkOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, hidden):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(hidden, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "id": "d9-qoKuTNwKq",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointwiseFeedForward(Layer):\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PointwiseFeedForward, self).__init__()\n",
        "        self.linear1 = Dense(hidden, activation='relu')\n",
        "        self.linear2 = Dense(d_model)\n",
        "        self.dropout = Dropout(rate=drop_prob)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cDUolDfP66vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fundamental Unit of Transformer encoder"
      ],
      "metadata": {
        "id": "B2RRmn2bOpW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads, hidden, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.attention = MultiHeadAttention(d_model, num_heads)\n",
        "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate=rate)\n",
        "\n",
        "        self.ffn = PointwiseFeedForward(d_model, hidden, drop_prob=rate)\n",
        "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout2 = Dropout(rate=rate)\n",
        "\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        residual_x = tf.identity(x)\n",
        "        x, _ = self.attention(x, x, x, mask)\n",
        "        x = self.dropout1(x, training=training)\n",
        "        x = self.norm1(residual_x + x)\n",
        "        residual_x = tf.identity(x)\n",
        "\n",
        "        x = self.ffn(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "        x = self.norm2(residual_x + x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "HNuoJoFWO335",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fundamental Unit of Transformer decoder"
      ],
      "metadata": {
        "id": "9i6Zh8gnPqdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class DecoderLayer(Layer):\n",
        "#     def __init__(self, d_model, num_heads, hidden, rate=0.1):\n",
        "#         super(DecoderLayer, self).__init__()\n",
        "\n",
        "#         self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "#         self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "#         # self.ffn = point_wise_feed_forward_network(d_model, hidden)\n",
        "#         self.ffn = PointwiseFeedForward(d_model, hidden, drop_prob=rate)\n",
        "\n",
        "#         self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "#         self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "#         self.layernorm3 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "#         self.dropout1 = Dropout(rate)\n",
        "#         self.dropout2 = Dropout(rate)\n",
        "#         self.dropout3 = Dropout(rate)\n",
        "\n",
        "\n",
        "#     def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "#         attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "#         attn1 = self.dropout1(attn1, training=training)\n",
        "#         out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "#         attn2, attn_weights_block2 = self.mha2(out1, enc_output, enc_output,  padding_mask)\n",
        "#         attn2 = self.dropout2(attn2, training=training)\n",
        "#         out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "#         ffn_output = self.ffn(out2)\n",
        "#         ffn_output = self.dropout3(ffn_output, training=training)\n",
        "#         out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "#         return out3, attn_weights_block1, attn_weights_block2\n",
        "class DecoderLayer(Layer):\n",
        "    def __init__(self, d_model, num_heads, hidden, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.attention1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.attention2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        # self.ffn = point_wise_feed_forward_network(d_model, hidden)\n",
        "        self.ffn = PointwiseFeedForward(d_model, hidden, drop_prob=rate)\n",
        "\n",
        "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.norm3 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = Dropout(rate=rate)\n",
        "        self.dropout2 = Dropout(rate=rate)\n",
        "        self.dropout3 = Dropout(rate=rate)\n",
        "\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        output1, attention_weights1 = self.attention1(x, x, x, look_ahead_mask)\n",
        "        output1 = self.dropout1(output1, training=training)\n",
        "        output1 = self.norm1(output1 + x)\n",
        "\n",
        "        output2, attention_weights2 = self.attention2(output1, enc_output, enc_output,  padding_mask)\n",
        "        output2 = self.dropout2(output2, training=training)\n",
        "        output2 = self.norm2(output2 + output1)\n",
        "\n",
        "        output3 = self.ffn(output2)\n",
        "        output3 = self.dropout3(output3, training=training)\n",
        "        output3 = self.norm3(output3 + output2)\n",
        "\n",
        "        return output3, attention_weights1, attention_weights2\n"
      ],
      "metadata": {
        "id": "7CVmvs6dPMRC",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder consisting of multiple EncoderLayer(s)"
      ],
      "metadata": {
        "id": "6zt5MUc_QNid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(self,  d_model, num_layers, num_heads, hidden, input_vocab_size, max_pos_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(max_pos_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, hidden, rate) for _ in range(num_layers)]\n",
        "\n",
        "        # self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        # x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "BrbnTwijQJ-h",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder consisting of multiple DecoderLayer(s)"
      ],
      "metadata": {
        "id": "4N5LrNrvRexg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(Layer):\n",
        "    def __init__(self, d_model, num_layers,  num_heads, hidden, target_vocab_size, max_pos_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(max_pos_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, hidden, rate) for _ in range(num_layers)]\n",
        "        self.dropout = Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "\n",
        "        return x, attention_weights\n"
      ],
      "metadata": {
        "id": "UmeqkZrIRbSB",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finally, the Transformer"
      ],
      "metadata": {
        "id": "lbMNK_bzSHnh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(Model):\n",
        "    def __init__(self, d_model, num_layers, num_heads, hidden, input_vocab_size, target_vocab_size, max_pos_input, max_pos_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(d_model, num_layers, num_heads, hidden, input_vocab_size, max_pos_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(d_model, num_layers, num_heads, hidden, target_vocab_size, max_pos_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights\n"
      ],
      "metadata": {
        "id": "FXHRG-o4R9Mc",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "UndsMPZXTdSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper-params\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "hidden = 512\n",
        "num_heads = 8\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "lMTZJdIoSbuy",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adam optimizer with custom learning rate scheduling"
      ],
      "metadata": {
        "id": "uOGvkYDNTjIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(LearningRateSchedule):  # Using the Adam optimizer with a custom learning rate scheduler according to the formula in the original Transformer paper.\n",
        "    def __init__(self, d_model, warmup_steps=4000): # lrate = d_model^-0.5 * min(step_num^-0.5, step_num * warmup_steps^-1.5)\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, dtype=tf.float32)\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step* (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "metadata": {
        "id": "tfiynCLlTL8C",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Defining losses and other metrics"
      ],
      "metadata": {
        "id": "DsVdrENTUERY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "Ip1-943kTXXK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "ktKwyvKtTvF6",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n"
      ],
      "metadata": {
        "id": "uW4LA_45T4Aa",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ],
      "metadata": {
        "id": "Ze0u6xxXT7dI",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer"
      ],
      "metadata": {
        "id": "9XvKy3v6ULnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = Transformer(\n",
        "    d_model,\n",
        "    num_layers,\n",
        "    num_heads,\n",
        "    hidden,\n",
        "    encoder_vocab_size,\n",
        "    decoder_vocab_size,\n",
        "    max_pos_input=encoder_vocab_size,\n",
        "    max_pos_target=decoder_vocab_size,\n",
        ")"
      ],
      "metadata": {
        "id": "d5-RcxqFUCuk",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Masks"
      ],
      "metadata": {
        "id": "f56BGiVXU_Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inputs, targets):\n",
        "    enc_padding_mask = create_padding_mask(inputs)\n",
        "    dec_padding_mask = create_padding_mask(inputs)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(targets)[1])\n",
        "#     look_ahead_mask = create_look_ahead_mask(75)\n",
        "\n",
        "    dec_target_padding_mask = create_padding_mask(targets)\n",
        "\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "metadata": {
        "id": "FZxHuyZxU5Pa",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checkpoints"
      ],
      "metadata": {
        "id": "SYIotvaBVI0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print('Latest checkpoint restored!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOc1_3c-VGaL",
        "outputId": "b6406ea7-0e8a-42b7-d520-db7e4fb1bcd1",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latest checkpoint restored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training steps"
      ],
      "metadata": {
        "id": "WfpI0gS4c06c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp,\n",
        "            True,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ],
      "metadata": {
        "id": "xmVOMzkrczgl",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    count = 0\n",
        "    for (batch, (inp, tar)) in enumerate(ds):\n",
        "        train_step(inp, tar)\n",
        "        # count+=1\n",
        "\n",
        "\n",
        "        # print('hi')\n",
        "        # 55k samples\n",
        "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
        "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
        "        if batch % 429 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
        "        # if count > 1:\n",
        "        #     raise Exception('yap')\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "\n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2J5R8m6qhtL",
        "outputId": "6013f840-64fb-4a75-ad39-a5bccb0a2b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 400, 128)\n",
            "(64, 400, 128)\n",
            "(64, 400, 128)\n",
            "(64, 400, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 400, 128)\n",
            "(64, 400, 128)\n",
            "(64, 400, 128)\n",
            "(64, 400, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "(64, 74, 128)\n",
            "Epoch 1 Batch 0 Loss 8.5961\n",
            "Epoch 1 Batch 429 Loss 5.3961\n",
            "Epoch 1 Batch 858 Loss 4.3236\n",
            "Epoch 1 Loss 4.3198\n",
            "Time taken for 1 epoch: 370.92382431030273 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 2.5660\n",
            "Epoch 2 Batch 429 Loss 2.2479\n",
            "Epoch 2 Batch 858 Loss 2.0138\n",
            "Epoch 2 Loss 2.0131\n",
            "Time taken for 1 epoch: 331.52879095077515 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.4927\n",
            "Epoch 3 Batch 429 Loss 1.4243\n",
            "Epoch 3 Batch 858 Loss 1.3569\n",
            "Epoch 3 Loss 1.3566\n",
            "Time taken for 1 epoch: 331.2192060947418 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 1.1613\n",
            "Epoch 4 Batch 429 Loss 1.0922\n",
            "Epoch 4 Batch 858 Loss 1.0670\n",
            "Epoch 4 Loss 1.0665\n",
            "Time taken for 1 epoch: 331.4067430496216 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.9217\n",
            "Epoch 5 Batch 429 Loss 0.9011\n",
            "Epoch 5 Batch 858 Loss 0.9005\n",
            "Saving checkpoint for epoch 5 at checkpoints/ckpt-5\n",
            "Epoch 5 Loss 0.9003\n",
            "Time taken for 1 epoch: 333.25147771835327 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "PVbEUCZagJ0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears"
      ],
      "metadata": {
        "id": "YMbqGTixu1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(input_news):\n",
        "    input_news = news_tokenizer.texts_to_sequences([input_news])\n",
        "    input_news = tf.keras.preprocessing.sequence.pad_sequences(input_news, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_news[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index['<start>']]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "\n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input,\n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index['<end>']:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n"
      ],
      "metadata": {
        "id": "F5D5cv2Jd8-6",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input_news):\n",
        "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
        "    summarized = evaluate(input_news=input_news)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <START> token\n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated news"
      ],
      "metadata": {
        "id": "UkpdiW6wnmiS",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def checkinbulk(randomnumber):\n",
        "  print('Actual summary:', summarize(news[randomnumber]))\n",
        "\n",
        "  print('News: ', news[randomnumber])\n",
        "  print('Actual summary: ', summary[randomnumber][7:-6])\n",
        "\n"
      ],
      "metadata": {
        "id": "Azfs-rvlTfOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_number = random.randint(0, 55104)\n",
        "\n",
        "checkinbulk(random_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_FUA-pqTfP6",
        "outputId": "e0e75aa2-9bbc-43c6-90d0-20f24b31c7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 11, 128)\n",
            "(1, 11, 128)\n",
            "(1, 11, 128)\n",
            "(1, 11, 128)\n",
            "(1, 11, 128)\n",
            "(1, 11, 128)\n",
            "(1, 11, 128)\n",
            "(1, 11, 128)\n",
            "Actual summary: mp 39 s 39 the most polluted indian city who\n",
            "News:  Madhya Pradesh&#39;s Gwalior is the most polluted Indian city in terms of air pollution, according to a World Health Organisation report. Indians living outside the Himalayan belt and Kashmir are exposed to air pollution beyond the WHO safe limits, the report added. Notably, Delhi does not feature in the list of the top ten most polluted Indian cities.\n",
            "Actual summary:   MP&#39;s Gwalior is the most polluted Indian city: WHO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v2aL5HPCTd2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(\n",
        "    \"A historic achievement has been made in the realm of space exploration. Astronomers have detected the presence of an Earth-like planet orbiting a distant star within the habitable zone. This exciting discovery raises the possibility of finding extraterrestrial life and provides valuable insights into the existence of other habitable worlds beyond our own. Scientists are now planning detailed observations and future missions to explore this intriguing exoplanet further. The discovery marks a significant milestone in our quest to unravel the mysteries of the universe and understand our place in the cosmos\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WZoEHvIxrYKZ",
        "outputId": "2abaa1f7-7771-4b77-cbe8-c847cc9f7cb3",
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 1, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 2, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 3, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 4, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 5, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 6, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 7, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 8, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 9, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 400, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n",
            "(1, 10, 128)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'newly made new space detected for earth like planet'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfg4SoaFYmUa",
        "outputId": "b3feb6e0-dfd7-4094-c754-3b1f9112ca2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_15 (Encoder)        multiple                  10567424  \n",
            "                                                                 \n",
            " decoder_15 (Decoder)        multiple                  4854912   \n",
            "                                                                 \n",
            " dense_4911 (Dense)          multiple                  3826269   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,248,605\n",
            "Trainable params: 19,248,605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kNVOWPXFIn0k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}